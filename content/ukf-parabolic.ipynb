{
  "metadata": {
    "hide_input": false,
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "widgets": {
      "state": {
        "f13ba74f0f494061a21f9e2645f87e54": {
          "views": [
            {
              "cell_index": 46
            }
          ]
        },
        "fd665b89e50547b7996532411b00e7a6": {
          "views": [
            {
              "cell_index": 52
            }
          ]
        }
      },
      "version": "1.2.0"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# UKF estimation of 3D parabolic motion from a single camera",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Debido a que las cónicas son proyectivamente equivalentes podría pensarse que la imagen de la trayectoria de un movimiento parabólico en una sola cámara no permite reconstruir la trayectoria 3D.\n\nSin embargo, si la cámara está calibrada y las posiciones observadas tienen medidas de tiempo, podemos aprovechar las leyes del movimiento para construir un estimador probabilístico capaz de recuperar el estado de movimiento 3D con mucha precisión. El modelo de observación es no lineal, por lo que utilizaremos el [UKF](https://en.wikipedia.org/wiki/Kalman_filter#Unscented_Kalman_filter).",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Cámara calibrada",
      "metadata": {
        "heading_collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": "%pip install ipywidgets\n%pip install ipympl\n\n%matplotlib widget\n\nimport cv2\nimport numpy as np\nimport numpy.linalg as la\nimport matplotlib.pyplot as plt\nfrom umucv.kalman import kalman, ukf\nimport umucv.htrans as ht\n\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom umucv.htrans import kgen, sepcam, jr, jc, col, row, htrans, lookat2, inhomog\nfrom ipywidgets import interact, IntSlider\n\ndegree = np.pi/180",
      "metadata": {
        "hidden": true,
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def clean(fig):\n    fig.canvas.toolbar_visible = False\n    fig.canvas.header_visible = False\n    fig.canvas.footer_visible = False\n    fig.canvas.capture_scroll = False\n\ndef fig3d(size=(6,5)):\n    fig = plt.figure(figsize=size)\n    plt.subplots_adjust(top=1)\n    clean(fig)\n    return fig, fig.add_subplot(111, projection='3d')\n\n#def plot3(ax,c,col):\n#    ax.plot(c[:,0],c[:,1],c[:,2],color=col)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def cameraOutline2(M, sc = 0.3):\n\n    K,R,C = sepcam(M)\n\n    # formamos una transformación 3D para mover la cámara en el origen a la posición de M\n    rt = jr(jc(R, -R @ col(C)),\n            row(0,0,0,1))\n\n    x = 1;\n    y = x;\n    z = 0.99;\n\n    ps =[x,    0,    z,\n         (-x), 0,    z,\n         0,    0,    z,\n         0,    1.3*y,z,\n         0,    (-y), z,\n         x,    (-y), z,\n         x,    y,    z,\n         (-x), y,    z,\n         (-x), (-y), z,\n         x,    (-y), z,\n         x,    y,    z,\n         0,    y,    z,\n         0,    0,    z,\n         0,    0,    0,\n         1,    1,    z,\n         0,    0,    0,\n         (-1), 1,    z,\n         0,    0,    0,\n         (-1), (-1), z,\n         0,    0,    0,\n         (1), (-1),  z,\n         0,    0,    0,\n         0,    0,    (2*x)]\n\n    ps = np.array(ps).reshape(-1,3)\n    return htrans(la.inv(rt), sc * ps)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def mkCov2p(p1,p2,thick=0.2):\n    d = np.array([p1,p2])\n    m = np.mean(d,axis=0)\n    c = np.cov(d,rowvar=False)\n    c = c + np.eye(len(p1)) * la.norm(np.array(p1)-np.array(p2))*thick\n    return m,c\n\nu = np.linspace(0.0, 2.0 * np.pi, 20)\nv = np.linspace(0.0, np.pi, 20)\nx_0 = np.outer(np.cos(u), np.sin(v))\ny_0 = np.outer(np.sin(u), np.sin(v))\nz_0 = np.outer(np.ones_like(u), np.cos(v))\n\ndef ellip3d(mc):\n    m,c = mc\n    l,r =la.eigh(c)\n    tran = np.diag(np.sqrt(abs(l))) @ r.T\n    return (np.array([x_0.flatten(),y_0.flatten(),z_0.flatten()]).T @ tran + m).T.reshape(3,len(u),len(v))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# check the uncertainty ellipsoid in 3D\nif False:\n    m,c = mkCov2p((0,0,0),(1,1,1),thick=0.1)\n    _, ax = fig3d((5,4))\n    ax.plot_surface( *ellip3d((m,c)), color='w');",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Generamos una trayectoria sintética.",
      "metadata": {
        "hidden": true
      }
    },
    {
      "cell_type": "code",
      "source": "x0 = np.array([0,0,0])\n\nangle1 = 20*degree\nangle2 = 80*degree\nv0 = 10*np.array([np.cos(angle1)*np.cos(angle2), np.sin(angle1)*np.cos(angle2), np.sin(angle2)])\n\na = np.array([0,0, - 9.8])\nt = np.arange(0,2.01,1/25)\n\nZt = xt,yt,zt = ht.col(x0)  +  ht.col(v0)* ht.row(t) + 1/2 * ht.col(a) * ht.row(t**2)",
      "metadata": {
        "hidden": true,
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Creamos una cámara sintética y mostramos la situación de la cámara y la trayectoria del objeto.",
      "metadata": {
        "hidden": true
      }
    },
    {
      "cell_type": "code",
      "source": "K = kgen((640,480),1.6)\nP =  lookat2((6,6,2),(0,0,2))  # a 2 metros de altura, apuntando horizontalmente\nM = K @ P\n\ncamline = cameraOutline2(M,0.5)",
      "metadata": {
        "hidden": true,
        "hide_input": false,
        "scrolled": true,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "_, ax = fig3d()\nax.plot(*camline.T,'blue',lw=1)\nax.plot(*Zt,'green')\nax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')\nax.view_init(elev=30., azim=-30);",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Las observaciones con las que vamos a trabajar son las imágenes del objeto contaminadas con ruido:",
      "metadata": {
        "hidden": true,
        "hide_input": false
      }
    },
    {
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(6,4))\nclean(fig)\nnoise = 2\nview = htrans(M,Zt.T) + noise*np.random.randn(len(t),2)\nplt.plot(view[:,0],view[:,1],'.-');\nplt.axis([0,640,480,0])\nplt.grid()",
      "metadata": {
        "hidden": true,
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Definimos la dinámica y el modelo de medida necesario para UKF. En este caso son directamente funciones en Python, aunque para la dinámica aprovechamos la estructura matricial. Para la observación se aplica la transformación proyectiva con la matriz de cámara, que suponemos conocida.",
      "metadata": {
        "hidden": true
      }
    },
    {
      "cell_type": "code",
      "source": "fps = 25\ndt  = 1/fps\n\nF = np.array(\n    [1, 0, 0, dt,  0,  0,\n     0, 1, 0,  0, dt,  0,\n     0, 0, 1,  0,  0, dt,\n     0, 0, 0,  1,  0,  0,\n     0, 0, 0,  0,  1,  0,\n     0, 0, 0,  0,  0,  1]).reshape(6,6)\n\nB = np.array(\n         [dt**2/2, 0,       0,\n          0,       dt**2/2, 0,\n          0,       0,       dt**2/2,\n          dt,      0,       0,\n          0,       dt,      0,\n          0,       0,       dt]).reshape(6,3)\n\n\ndef f(x):\n    return F@x + B@a\n\ndef h(x):\n    return htrans(M,x[:3])\n\ndef b(x):\n    return 0",
      "metadata": {
        "hidden": true,
        "hide_input": true,
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Y hacemos una simulación de los primeros N frames, mostrando el elipsoide de incertidumbre de la posición en el último de ellos. (En este ejemplo no mostramos la predicción en el futuro).",
      "metadata": {
        "hidden": true
      }
    },
    {
      "cell_type": "code",
      "source": "mu = mu0 = np.array([0,0,0,0,0,0])\n\nP = P0 = np.diag([1,1,1,10,10,10])**2\n\n\nsigmaM = 0.001   # ruido del modelo\nsigmaZ = noise   # pixel\n\nQ = sigmaM**2 * np.eye(6)\nR = sigmaZ**2 * np.eye(2)\n\n\n# p.ej. prueba con 10, 35, 45. Cada vez se va acortando más el elipsoide de incertidumbre.\nN = 60\n\nres = [(mu,P,mu)]\nres=[]\n\n# mu es la estimación filtrada actualizada\nfor z in view[:N]:\n    mu,P,pred = ukf(mu,P,f,Q,b,a,z,h,R)\n    res += [(mu,P,pred)]",
      "metadata": {
        "hidden": true,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "xe = [mu[0] for mu,_,_ in res] # coordenadas estimadas\nye = [mu[1] for mu,_,_ in res]\nze = [mu[2] for mu,_,_ in res]\n\nmul,Pl,_ = res[-1]\nex,ey,ez = ellip3d((mul[:3],Pl[:3,:3]))",
      "metadata": {
        "hidden": true,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "fig, ax = fig3d()\nax.plot(*camline.T,'blue',lw=1)\nax.plot(*Zt,'green')\nax.plot(xe,ye,ze,'red')\nsurf = ax.plot_surface(ex, ey, ez, color='black');\nax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')\nax.view_init(elev=30., azim=-30);\naxs = plt.axis(); zls = ax.get_zlim3d()\n\ndef movepos(k):\n    global surf\n    mul,Pl,_ = res[k]\n    ex,ey,ez = ellip3d((mul[:3],Pl[:3,:3]))\n    surf.remove()\n    surf = ax.plot_surface(ex, ey, ez, color='black');\n    plt.axis(axs); ax.set_zlim3d(zls);\n    fig.canvas.draw()\n\ninteract(movepos, k=IntSlider(min=0, max=len(res)-1, step=1, value=10));",
      "metadata": {
        "hidden": true,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "En este experimento se asume una cámara completamente calibrada y situada de forma conocida. Esto puede no ser fácil de conseguir en aplicaciones prácticas.",
      "metadata": {
        "hidden": true
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Estimación de orientación",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Lo interesante sería estimar de la misma forma los ángulos de roll y tilt (o equivalentemente la dirección de la gravedad respecto al sistema de la cámara). Experimentos preliminares indican que el roll puede estimarse con robustez aceptable pero el tilt es más complicado.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Roll",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Trayectoria ground truth:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "x0 = np.array([0,0,0])\n\nangle1 = 20*degree\nangle2 = 80*degree\nv0 = 10*np.array([np.cos(angle1)*np.cos(angle2), np.sin(angle1)*np.cos(angle2), np.sin(angle2)])\n\na = np.array([0,0, - 9.8])\n\nFPS=30\n\nt = np.arange(0,2.01,1/FPS)\n\nZt = xt,yt,zt = ht.col(x0)  +  ht.col(v0)* ht.row(t) + 1/2 * ht.col(a) * ht.row(t**2)",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Creamos una cámara sintética y mostramos la situación de la cámara y la trayectoria del objeto.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def R1(x):\n    return ht.rotation((1,0,0),x)\n\ndef R2(x):\n    return ht.rotation((0,1,0),x)\n\ndef R3(x):\n    return ht.rotation((0,0,1),x)\n\nGT_TILT = 0\nGT_ROLL = 10\n\nK = kgen((640,480),1.6)\nP =  lookat2((6,6,2),(0,0,2))  # a 2 metros de altura, apuntando horizontalmente\nM =  K @ R1(np.radians(GT_TILT)) @ R2(np.radians(0)) @ R3(np.radians(GT_ROLL)) @ P\nMe = K @ P\n\ncamline = cameraOutline2(M,sc=0.7)\n\nfig,ax = fig3d()\nax.plot(*camline.T,'blue',lw=1)\nax.plot(*Zt,'green')\nax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')\nax.view_init(elev=30., azim=-40)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Las observaciones con las que vamos a trabajar son las imágenes del objeto contaminadas con ruido:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(4,3))\nclean(fig)\nnoise = 1/2\nview = htrans(M,Zt.T) + noise*np.random.randn(len(t),2)\nplt.plot(view[:,0],view[:,1],'.-');\nplt.axis([0,640,480,0]); plt.grid();",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Definimos la dinámica y el modelo de medida necesario para UKF. En este caso son directamente funciones en Python.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "fps = FPS\ndt  = 1/fps\n\nF = np.array(\n    [1, 0, 0, dt,  0,  0,\n     0, 1, 0,  0, dt,  0,\n     0, 0, 1,  0,  0, dt,\n     0, 0, 0,  1,  0,  0,\n     0, 0, 0,  0,  1,  0,\n     0, 0, 0,  0,  0,  1]).reshape(6,6)\n\nB = np.array(\n         [dt**2/2, 0,       0,\n          0,       dt**2/2, 0,\n          0,       0,       dt**2/2,\n          dt,      0,       0,\n          0,       dt,      0,\n          0,       0,       dt]).reshape(6,3)\n\n\ndef f(x):\n    return np.hstack([F@x[:6] + B@a , x[6:]])\n\n\n\ndef h(x):\n    C = K @ R1(0) @  R3(x[6])  @ la.inv(K) @ Me\n    return htrans(C ,x[:3])\n\ndef b(x):\n    return 0",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Y hacemos una simulación de los primeros N frames, mostrando el elipsoide de incertidumbre de la posición en el último de ellos. (En este ejemplo no mostramos la predicción en el futuro).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "mu = np.array([0,1,0,0,0,0,0,0])\nP  = np.diag([2,2,2,10,10,10,np.radians(10),np.radians(10)])**2\n\nres = [(mu,P,None)]\n\nsigmaM = 0.001   # ruido del modelo\nsigmaZ = 1*noise   # pixel\n\nQ = sigmaM**2 * np.eye(len(mu))\nR = sigmaZ**2 * np.eye(2)\n\nfor z in view:\n    mu,P,pred = ukf(mu,P,f,Q,b,a,z,h,R)\n    res += [(mu,P,pred)]\n\nxe = [mu[0] for mu,_,_ in res]\nye = [mu[1] for mu,_,_ in res]\nze = [mu[2] for mu,_,_ in res]\n\n\n\nmul,Pl,_ = res[0]\nex,ey,ez = ellip3d((mul[:3],Pl[:3,:3]))\n\nC = K @ R1(mul[7]) @  R3(mul[6])  @ la.inv(K) @ Me\n\nfinalcamline = cameraOutline2(C,sc=1)\n\nfig2,ax2 = fig3d()\nax2.plot(*finalcamline.T,'blue',lw=1)\nax2.plot(*Zt,'green')\nax2.plot(xe,ye,ze,'red')\nsurf2 = ax2.plot_surface(ex, ey, ez, color='w');\nax2.set_xlabel('X'); ax2.set_ylabel('Y'); ax2.set_zlabel('Z')\nax2.axis([0,6,0,6])\nax2.set_zlim3d(0,6)\nax2.view_init(elev=30., azim=-30)\n\ndef movepos_2(k):\n    global surf2\n    mul,Pl,_ = res[k]\n    ex,ey,ez = ellip3d((mul[:3],Pl[:3,:3]))\n    surf2.remove()\n    surf2 = ax2.plot_surface(ex, ey, ez, color='w');\n\n    plt.axis(axs); ax2.set_zlim3d(zls);\n    fig2.canvas.draw()\n\ninteract(movepos_2, k=IntSlider(min=0, max=len(res)-1, step=1, value=1));",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(5,4))\nclean(fig)\nplt.plot(np.sum(abs(np.array([pred for _,_,pred in res[1:]]) - view),axis=1));\nplt.axis([0,len(view),0,20]);\nplt.title('prediction error');\nplt.xlabel('frame'); plt.ylabel('pixels');",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(6,4))\nclean(fig)\nviewpred = np.array([pred for _,_,pred in res[1:]])\nplt.plot(view[:,0],view[:,1],'-',lw=3)\nplt.plot(viewpred[:,0],viewpred[:,1],'-');\nplt.axis([0,640,480,0]); plt.grid(ls='dotted');\nplt.title('predicted vs observed');",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(5,4))\nclean(fig)\nplt.plot(np.degrees([res[k][0][-2] for k in range(1,len(res))]));\nplt.plot([0,len(res)],[GT_ROLL,GT_ROLL],ls='dashed',color='gray');\nplt.title('estimated roll'); plt.xlabel('frame'); plt.ylabel('degree');",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Tilt",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "GT_TILT = 5\nGT_ROLL = 0\n\nK = kgen((640,480),1.6)\nP =  lookat2((6,6,2),(0,0,2))  # a 2 metros de altura, apuntando horizontalmente\nM =  K @ R1(np.radians(GT_TILT)) @ R2(np.radians(0)) @ R3(np.radians(GT_ROLL)) @ P\nMe = K @ P\n\ncamline = cameraOutline2(M,sc=0.7)\n\nfig,ax = fig3d()\nax.plot(*camline.T,'blue',lw=1)\nax.plot(*Zt,'green')\nax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')\nax.view_init(elev=30., azim=-40)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Observaciones:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(4,3))\nclean(fig)\nnoise = 1/2\nview = htrans(M,Zt.T) + noise*np.random.randn(len(t),2)\nplt.plot(view[:,0],view[:,1],'.-');\nplt.axis([0,640,480,0]); plt.grid();",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Modelo de medida:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def h(x):\n    C = K @ R1(x[7]) @  R3(0)  @ la.inv(K) @ Me\n    return htrans(C ,x[:3])",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Estimación:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "mu = np.array([0,1,0,0,0,0,0,0])\nP  = np.diag([2,2,2,10,10,10,np.radians(10),np.radians(10)])**2\n\nres = [(mu,P,None)]\n\nsigmaM = 0.001   # ruido del modelo\nsigmaZ = 1*noise   # pixel\n\nQ = sigmaM**2 * np.eye(len(mu))\nR = sigmaZ**2 * np.eye(2)\n\nfor z in view:\n    mu,P,pred = ukf(mu,P,f,Q,b,a,z,h,R)\n    res += [(mu,P,pred)]\n\n\nxe = [mu[0] for mu,_,_ in res]\nye = [mu[1] for mu,_,_ in res]\nze = [mu[2] for mu,_,_ in res]\n\n\n\nmul,Pl,_ = res[0]\nex,ey,ez = ellip3d((mul[:3],Pl[:3,:3]))\n\nC = K @ R1(mul[7]) @  R3(mul[6])  @ la.inv(K) @ Me\n\nfinalcamline = cameraOutline2(C,sc=1)\n\nfig3,ax3 = fig3d()\nax3.plot(*finalcamline.T,'blue',lw=1)\nax3.plot(*Zt,'green')\nax3.plot(xe,ye,ze,'red')\nsurf3 = ax3.plot_surface(ex, ey, ez, color='w');\nax3.set_xlabel('X'); ax3.set_ylabel('Y'); ax3.set_zlabel('Z')\nax3.axis([0,6,0,6])\nax3.set_zlim3d(0,6)\nax3.view_init(elev=30., azim=-30)\n\ndef movepos_3(k):\n    global surf3\n    mul,Pl,_ = res[k]\n    ex,ey,ez = ellip3d((mul[:3],Pl[:3,:3]))\n    surf3.remove()\n    surf3 = ax3.plot_surface(ex, ey, ez, color='w');\n    plt.axis(axs); ax3.set_zlim3d(zls);\n    fig3.canvas.draw()\n\ninteract(movepos_3, k=IntSlider(min=0, max=len(res)-1, step=1, value=1));",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(5,4))\nclean(fig)\nplt.plot(np.sum(abs(np.array([pred for _,_,pred in res[1:]]) - view),axis=1));\nplt.axis([0,len(view),0,20]);\nplt.title('prediction error');\nplt.xlabel('frame'); plt.ylabel('pixels');",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(6,4))\nclean(fig)\nviewpred = np.array([pred for _,_,pred in res[1:]])\nplt.plot(view[:,0],view[:,1],'-',lw=3)\nplt.plot(viewpred[:,0],viewpred[:,1],'-');\nplt.axis([0,640,480,0]); plt.grid(ls='dotted');\nplt.title('predicted vs observed');",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(5,4))\nclean(fig)\nplt.plot(np.degrees([res[k][0][-1] for k in range(1,len(res))]));\nplt.plot([0,len(res)],[GT_TILT,GT_TILT],ls='dashed',color='gray');\nplt.title('estimated tilt'); plt.xlabel('frame'); plt.ylabel('degree');",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "El tilt es más complicado de detectar. Con tilt 10º y noise 0.1 se consigue buen error de predicción, aunque el tilt estimado se aproxima lentamente a 10. Algo parecido ocurre con tilt 5º y noise 1/2. Puede predecir aceptablemente bien aunque el ángulo no sea preciso. Esto significa que esa variable de estado es \"menos observable\".\n\nSin embargo el roll es más robusto, aguanta 10 grados con noise 1/2.",
      "metadata": {}
    }
  ]
}