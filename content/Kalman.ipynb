{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "# Filtro de Kalman\n",
    "<span style=\"color: gray\">dic 2019</span><br>\n",
    "[*Alberto Ruiz*](http://dis.um.es/profesores/alberto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La inferencia Bayesiana puede realizarse de forma analítica cuando las variables involucradas son [normales](https://en.wikipedia.org/wiki/Multivariate_normal_distribution) (gaussianas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Modelo gaussiano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Las operaciones de marginalización, condicionamiento y conjunción pueden calcularse de forma analítica cuando las variables son normales.\n",
    "\n",
    "Son el fundamento del filtro de Kalman y de los [procesos gaussianos](https://en.wikipedia.org/wiki/Gaussian_process), entre otras muchas aplicaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "El [artículo de wikipedia](https://en.wikipedia.org/wiki/Kalman_filter) está bastante bien. Puede ser útil repasar los apartados C.5 y C.6 de mis antiguos [apuntes](http://dis.um.es/profesores/alberto/material/percep.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Expresiones analíticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Si reordenamos las variables en dos grupos $(\\boldsymbol x, \\boldsymbol y)$ la densidad conjunta se puede expresar en función de las medias y matrices de covarianza de cada grupo y la covarianza cruzada:\n",
    "\n",
    "$$ \n",
    "\\newcommand{\\mat}[1]{\\boldsymbol{\\mathtt #1}}\n",
    "\\newcommand{\\T}{^\\mathsf T}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\I}{^{-1}}\n",
    "p(\\vec x, \\vec y) \\sim \\mathcal N\\left(\\begin{bmatrix}\\vec \\mu_x \\\\ \\vec \\mu_y\\end{bmatrix}, \\begin{bmatrix}\\Sigma_{xx} & \\Sigma_{xy} \\\\ \\Sigma_{yx} & \\Sigma_{yy} \\end{bmatrix}\\right) = \\mathcal N \\left(\\begin{bmatrix}\\vec a \\\\ \\vec b\\end{bmatrix}, \\begin{bmatrix}\\mat A & \\mat C\\T \\\\ \\mat C & \\mat B \\end{bmatrix}\\right) $$\n",
    "\n",
    "\n",
    "La densidad **marginal** de cualquier grupo se obtiene simplemente seleccionando las variables deseadas tanto en la media como en la matriz de covarianza. Por ejemplo:\n",
    "\n",
    "$$p(\\vec y) \\sim  \\mathcal N \\left(\\vec b, \\mat B\\right) $$\n",
    "\n",
    "\n",
    "La densidad de un grupo de variables **condicionada** a la observación de otro grupo de variables es también gaussiana y se puede expresar de la siguiente forma:\n",
    "\n",
    "$$\n",
    "p(\\vec y \\mid \\vec x) \\sim \\mathcal N \\left(\\vec b + \\mat C \\mat A\\I (\\vec x - \\vec a)\\; , \\; \\mat B - \\mat C \\mat A\\I \\mat C\\T\\right)\n",
    "$$\n",
    "\n",
    "(La media condicionada de esta gaussiana es la recta de regresión lineal).\n",
    "\n",
    "En ocasiones estamos interesados realizar inferencia sobre unas variables $\\vec x$ a partir de la observación de una cierta función de ellas: $\\vec y = f(\\vec x)$. Si $\\vec x$ es gaussiana y la función $f$ es lineal podemos obtener fácilmente la densidad **conjunta** $p(\\vec x,\\vec y)$, que también es gaussiana, y realizar el condicionamiento como se acaba de explicar.\n",
    "\n",
    "Concretamente, sea $p(\\vec x) \\sim \\mathcal N (\\vec \\mu, \\mat P)$ y $f(\\vec x) = \\mat H \\vec x$ con ruido gaussiano aditivo de media $\\vec o$ y covarianza $\\mat R$. Esto significa que $p(\\vec y| \\vec x) \\sim \\mathcal N(\\mat H \\vec x + \\vec o, \\mat R)$. Entonces la densidad conjunta es:\n",
    "\n",
    "$$\n",
    "p(\\vec x, \\vec y) \\sim \\mathcal N\\left(\\begin{bmatrix}\\vec \\mu \\\\ \\mat H \\vec \\mu + \\vec o\\end{bmatrix}, \\begin{bmatrix}\\mat P & \\mat P \\mat H\\T \\\\ \\mat H \\mat P & \\mat H \\mat P \\mat H\\T + \\mat R\\end{bmatrix}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Y la densidad condicionada contraria $p(\\vec x \\mid \\vec y)$ es:\n",
    "\n",
    "$$p(\\vec x \\mid \\vec y) \\sim \\mathcal N \\left(\\vec \\mu + \\mat K (\\vec y - \\mat H \\vec \\mu - \\vec o) , (\\mat I - \\mat K \\mat H )\\mat P \\right)$$\n",
    "\n",
    "donde\n",
    "\n",
    "$$ \\mat K= \\mat P \\mat H\\T (\\mat H \\mat P \\mat H\\T + \\mat R)\\I $$\n",
    "\n",
    "Esta expresión está construida de manera que a partir de la observación $\\vec y$\n",
    "corregimos la información sobre $\\vec x$ con una \"ganancia de Kalman\" $\\mat K$ que depende\n",
    "del balance entre la incertidumbre a priori $\\mat P$, el ruido de la medida $\\mat R$, y el modelo de medida $\\mat H$.\n",
    "\n",
    "\n",
    "Otra forma de verlo: la densidad conjunta se puede expresar de dos formas: modelo de medida $\\times$ prior = posterior $\\times$ evidencia\n",
    "\n",
    "$$p(\\vec y \\mid \\vec x) \\; p(\\vec x)  =  p(\\vec x \\mid \\vec y) \\;  p(\\vec y) $$\n",
    "\n",
    "$$\\mathcal N (\\vec y \\mid \\mat H \\vec x + \\vec o, \\mat R) \\;\n",
    "\\mathcal N (\\vec x \\mid \\vec \\mu, \\mat P) =\n",
    "\\mathcal N (\\vec x \\mid \\vec \\eta_{\\vec y}, \\mat Q) \\;\n",
    "\\mathcal N (\\vec y \\mid \\mat H \\vec \\mu + \\vec o, \\mat H \\mat P \\mat H\\T + \\mat R)$$\n",
    "\n",
    "\n",
    "La incertidumbre inicial sobre $\\vec x$ era $\\mat P$, que se reduce a $\\mat Q$ tras la observación de $\\vec y$:\n",
    "\n",
    "$$ \\mat Q\\I = \\mat P\\I + \\mat H\\T \\mat R\\I \\mat H $$\n",
    "\n",
    "Y el estimador de $\\vec x$ se actualiza de $\\vec \\mu$ a $\\vec \\eta _ {\\vec y}$, que puede expresarse como una combinación ponderada de la observación y la información a priori:\n",
    "\n",
    "$$\\vec \\eta _ {\\vec y} = (\\mat Q \\mat H\\T \\mat R\\I) (\\vec y -\\vec o) + (\\mat Q \\mat P\\I) \\vec \\mu $$\n",
    "\n",
    "La \"evidencia\" $p(\\vec y)$ es la verosimilitud de la medida $\\vec y$ teniendo en cuenta todos los posibles $\\vec x$ (convolución de dos gaussianas). Juega un papel esencial en la selección de modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Para hacer experimentos usaremos una implementación de estas operaciones disponible en `umucv.prob`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from   mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from umucv.prob import G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "En primer lugar veremos un ejemplo muy simple. Considera la siguiente gaussiana de dos componentes, cuya densidad se muestra como una superficie en 3D y como una elipse de incertidumbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g = G([2,3], [[4,3],\n",
    "              [3,4]])\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "x = np.linspace(-3,7,50)\n",
    "y = np.linspace(-2,8,50)\n",
    "x1,x2 = np.meshgrid(x,y)\n",
    "gxy = g.logprob()\n",
    "z = np.array([[np.exp(gxy(np.array([x,y]))) for x in x] for y in y])\n",
    "\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax.plot_surface(x1,x2,z, cmap='coolwarm', linewidth=0.5, rstride=2, cstride=2);\n",
    "ax.view_init(elev=40,azim=90)\n",
    "ax.set_xlabel('x'); ax.set_ylabel('y'); ax.set_title('p(x,y)'); ax.set_zticks([])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(*g.ellipse().T);\n",
    "plt.plot(*g.m,'.');\n",
    "plt.xlabel('x'); plt.ylabel('y'); plt.title('elipse de incertidumbre'); plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "En el siguiente diagrama se muestra la densidad conjunta $p(x,y)$, las dos densidades marginales, y la densidad de $x$ condicionada a un valor de y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(*g.ellipse().T, label='$p(x,y)$');\n",
    "px = g.marg([0]).logprob()\n",
    "py = g.marg([1]).logprob()\n",
    "plt.plot(x, [-3+10*np.exp(px(x)) for x in x], label='p(x)');\n",
    "plt.plot([-4+10*np.exp(py(y)) for y in y], y, label='p(y)');\n",
    "gx = g.cond([6]).logprob()\n",
    "plt.plot(x, [-3+10*np.exp(gx(x)) for x in x], label='p(x|y=6)');\n",
    "plt.plot([-4,7],[6,6],ls='dashed',color='gray');\n",
    "plt.xlabel('x'); plt.ylabel('y'); plt.axis('equal');\n",
    "plt.legend(loc=(1.04,0), fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La misma situación en 3D, donde se muestra el corte producido por la observación $y=5$ en la densidad conjunta, (verosimilitud o likelihood), y la probabilidad condicionada, que es simplemente la normalización del corte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(x1,x2,z, cmap='coolwarm', linewidth=0.5, rstride=1, cstride=1);\n",
    "ax.view_init(elev=50,azim=60)\n",
    "ax.set_xlabel('x'); ax.set_ylabel('y'); ax.set_title('p(x,y)'); ax.set_zticks([])\n",
    "\n",
    "\n",
    "yobs = 5\n",
    "\n",
    "z6 = [np.exp(gxy(np.array([x,yobs]))) for x in x]\n",
    "\n",
    "ax.plot3D(x, yobs+x*0, z6, label=\"$p(x , y=5)$\");\n",
    "ax.plot3D(x, x*0+8, [1/5*np.exp(gx(x)) for x in x],label=\"$p(x\\mid y=5)$\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Veamos ahora la densidad conjunta de una variable $x\\sim \\mathcal N[0,2]$ y una función lineal de ella $y = 2x + 5 + \\mathcal N[0,1]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g = G([0],[[4]]).jointLinear([[2]], G([5], [[1]]))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(*g.ellipse().T); plt.axis('equal'); plt.grid(ls='dotted');\n",
    "plt.xlabel('x'); plt.ylabel('y');\n",
    "print(g.m)\n",
    "print(g.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Calculamos la densidad condicionada a y=0 a partir de la densidad conjunta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# se condiciona los últimos elementos del vector\n",
    "g = g.cond([0])\n",
    "g.m, g.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Y hacemos lo mismo con la fórmula directa que usa la ganancia K, sin pasar por la densidad conjunta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g = G([0],[[4]]).bayesGaussianLinearK([[2]], G([5],[[1]]), [0])\n",
    "g.m, g.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Veamos ahora un caso más interesante, donde $\\vec x$ tiene dos componentes, que observamos con ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g = G([0,0] , [[4,3],\n",
    "               [3,4]])\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(*g.ellipse().T); plt.axis('equal'); plt.grid(ls='dotted');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La densidad conjunta \"estado\"-\"observación\" es de dimensión 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error = np.diag([0.4,0.1])\n",
    "g.jointLinear(np.eye(2), G([0,0], error)).c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Dada una observación reducimos la incertidumbre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "obs = [0,-3]\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.axis('equal');\n",
    "post = g.bayesGaussianLinear(np.eye(2), G([0,0], error),  obs )\n",
    "plt.plot(*g.ellipse().T, label='prior');\n",
    "plt.plot(*post.ellipse().T, label='posterior', color='blue');\n",
    "plt.plot(*G(obs,  error).ellipse().T, label='likelihood');\n",
    "plt.grid(ls='dotted'); plt.legend(loc=(1.04,0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "El siguiente ejemplo es la clave del filtro de Kalman: el estado tiene dos variables $(x,y)$, pero la observación es incompleta $z=x+y$ y ruidosa. También reduce la incertidumbre sobre el estado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "post = g.bayesGaussianLinear([[1,1]], G([0], [[0.4]]),  [2] )\n",
    "plt.plot(*g.ellipse().T, label='prior');\n",
    "plt.plot(*post.ellipse().T, label='posterior', color='blue');\n",
    "plt.grid(ls='dotted'); plt.legend(loc=(1.04,0));\n",
    "plt.plot([-2,4],[4,-2],color='gray',ls='dashed');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Una implementación sencilla del filtro de Kalman y del UKF está disponible en el módulo `umucv.kalman`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "from umucv.kalman import kalman, ukf\n",
    "import cv2\n",
    "import umucv.htrans as ht\n",
    "\n",
    "degree = np.pi/180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Por comodidad la incluímos aquí:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def mikalman(mu,P,F,Q,B,u,z,H,R):\n",
    "    # mu, P : estado actual y su incertidumbre\n",
    "    # F, Q  : sistema dinámico y su ruido\n",
    "    # B, u  : control model y la entrada\n",
    "    # z     : observación\n",
    "    # H, R  : modelo de observación y su ruido\n",
    "\n",
    "    mup = F @ mu + B @ u;\n",
    "    pp  = F @ P @ F.T + Q;\n",
    "\n",
    "    zp = H @ mup\n",
    "\n",
    "    # si no hay observación solo hacemos predicción\n",
    "    if z is None:\n",
    "        return mup, pp, zp\n",
    "\n",
    "    epsilon = z - zp\n",
    "\n",
    "    k = pp @ H.T @ np.linalg.inv(H @ pp @ H.T +R)\n",
    "\n",
    "    new_mu = mup + k @ epsilon;\n",
    "    new_P  = (np.eye(len(P))-k @ H) @ pp;\n",
    "    return new_mu, new_P, zp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Ilustración 1-D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Vamos a resolver un problema sintético en el que un objeto se mueve en una única dimensión $x$ con una aceleración constante $a$. Desconocemos la velocidad inicial $v_0$ y solo observamos su posición a lo largo del tiempo, contaminada con ruido gaussiano de desviación $\\sigma_r$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "v0 = 0.5\n",
    "a = -0.005\n",
    "dt = 1\n",
    "t = np.arange(0,100,dt)\n",
    "\n",
    "sigmaR = 1\n",
    "zp = v0*t + 1/2*a*t**2\n",
    "zs = zp + sigmaR*np.random.randn(len(t));\n",
    "\n",
    "plt.plot(t,zs);\n",
    "plt.title(\"observaciones ruidosas de la posición\"); plt.xlabel(\"t\"); plt.ylabel(\"x\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "El modelo del sistema es el siguiente:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x_{k+1} &= x_k + \\Delta t \\; v_k \\\\\n",
    "v_{k+1} &= v_k \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Suponiendo $\\Delta t=1$, lo expresamos en forma matricial como transformaciones lineales del vector de estado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# modelo de evolución del sistema\n",
    "f = np.array(\n",
    "    [[1, dt],\n",
    "     [0,  1]])\n",
    "\n",
    "# control\n",
    "B = np.array([[dt**2/2],[dt]])\n",
    "u = np.array([a])\n",
    "\n",
    "# el ruido del proceso se puede poner como incertidumbre en la aceleración\n",
    "sigmaa = np.array([[abs(a/100)]])\n",
    "s = B @ sigmaa**2 @ B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#modelo de la observación\n",
    "H = np.array([[1,0]])\n",
    "\n",
    "#y su ruido\n",
    "r = np.array([[sigmaR**2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#el estado inicial\n",
    "mu0 = np.array([5,0])\n",
    "\n",
    "p0 = np.array(\n",
    "    [[100000, 0],\n",
    "     [0, 100000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Calculamos la estimación del vector de estado (posición y velocidad) para cada nueva observación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mu = mu0\n",
    "p = p0\n",
    "\n",
    "res = np.array([[mu[0],mu[1],np.sqrt(p[0,0]),np.sqrt(p[1,1])]])\n",
    "\n",
    "for z in zs:\n",
    "    mu,p,_ = kalman(mu,p,f,s,B,u,z,H,r)\n",
    "    res = np.append(res,[[mu[0],mu[1],np.sqrt(p[0,0]),np.sqrt(p[1,1])]],axis=0)\n",
    "\n",
    "print(res[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(res[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(t,zs,t,zp);\n",
    "plt.plot(t,res[1:,0],t,res[1:,0] + 2*res[1:,2],t,res[1:,0] - 2*res[1:,2],color='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(t,zs,t,zp,t,res[1:,0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Predicción sin observación: en un momento dado se pierden las medidas y la estimación se hace \"a ciegas\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mu = mu0\n",
    "p = p0\n",
    "\n",
    "res = np.array([[mu[0],mu[1],np.sqrt(p[0,0]),np.sqrt(p[1,1])]])\n",
    "\n",
    "ran = 50\n",
    "\n",
    "for z in zs[:ran]:\n",
    "    mu,p,_ = kalman(mu,p,f,s,B,u,z,H,r)\n",
    "    res = np.append(res,[[mu[0],mu[1],np.sqrt(p[0,0]),np.sqrt(p[1,1])]],axis=0)\n",
    "\n",
    "for z in zs[ran:]:\n",
    "    mu,p,_ = kalman(mu,p,f,s,B,u,None,H,r)\n",
    "    res = np.append(res,[[mu[0],mu[1],np.sqrt(p[0,0]),np.sqrt(p[1,1])]],axis=0)\n",
    "\n",
    "# extraemos las varianzas de la estimación de posición\n",
    "# para dibujar la banda de incertidumbre\n",
    "plt.plot(t[:ran],zs[:ran],t,zp);\n",
    "plt.plot(t,res[1:,0],t,res[1:,0] + 2*res[1:,2],t,res[1:,0] - 2*res[1:,2],color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Evolución de las elipses de incertidumbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from umucv.prob import G\n",
    "\n",
    "g0 = G(np.array([5,0]),\n",
    "       np.array([[100, 0],\n",
    "                 [0, 100]]))\n",
    "\n",
    "def showkalman2(g,z):\n",
    "    g1 = G( f @ g.m + B @ u  ,    f @ g.c @ f.T + s );\n",
    "    m,c,_ = kalman(g.m,g.c,f,s,B,u,z,H,r)\n",
    "    g2 = G(m,c)\n",
    "    plt.plot(*g1.ellipse().T,color='green');\n",
    "    if z is not None:\n",
    "        plt.plot(*g2.ellipse().T,color='blue');\n",
    "    return g2\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(*g0.ellipse().T,color='orange');\n",
    "g = g0\n",
    "for z in [12,23,36,47,None,None]:\n",
    "    g = showkalman2(g,z)\n",
    "plt.axis('equal'); plt.xlabel('x'); plt.ylabel('v');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tiro parabólico 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[Tiro parabólico](http://hyperphysics.phy-astr.gsu.edu/hbase/traj.html#tra6).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "TFG de Pablo Saura (UMU, 2017).\n",
    "\n",
    "- [vídeo 1](https://www.youtube.com/watch?v=MxwVwCuBEDA)\n",
    "\n",
    "- [vídeo 2](https://www.youtube.com/watch?v=YlPOTxYvt6U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x0 = np.array([0,0])\n",
    "angle = 80*degree\n",
    "v0 = 10*np.array([np.cos(angle), np.sin(angle)])\n",
    "\n",
    "a = np.array([0, - 9.8])\n",
    "t = np.arange(0,2.01,0.1)\n",
    "\n",
    "Z = xp,yp = ht.col(x0)  +  ht.col(v0)* ht.row(t) + 1/2 * ht.col(a) * ht.row(t**2)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(xp,yp,'.-',markersize=10);\n",
    "plt.axis('equal'); plt.grid(); plt.xlabel('$x$ (m)'); plt.ylabel('$y$ (m)');\n",
    "plt.title('trayectoria ideal ($\\Delta t = 0.1s$)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fps = 25\n",
    "dt  = 1/fps\n",
    "\n",
    "F = np.array(\n",
    "    [1, 0,  dt,  0,\n",
    "     0, 1,  0, dt,\n",
    "     0, 0,  1,  0,\n",
    "     0, 0,  0,  1 ]).reshape(4,4)\n",
    "\n",
    "\n",
    "B = np.array(\n",
    "         [dt**2/2, 0,\n",
    "          0,       dt**2/2,\n",
    "          dt,      0,\n",
    "          0,       dt      ]).reshape(4,2)\n",
    "\n",
    "\n",
    "H = np.array(\n",
    "    [1,0,0,0,\n",
    "     0,1,0,0]).reshape(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def evol(x,u):\n",
    "    return F@x + B@u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s0 = np.hstack([x0,v0])\n",
    "\n",
    "r = [s0]\n",
    "s = s0\n",
    "for k in range(round(2/dt)):\n",
    "    s = evol(s,a)\n",
    "    r.append(s)\n",
    "    #print(s)\n",
    "r = np.array(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xt,yt,*vs = r.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(xt,yt,'.-',markersize=10); plt.axis('equal'); plt.grid();\n",
    "plt.xlabel('$x$ (m)'); plt.ylabel('$y$ (m)');\n",
    "plt.title('comprobación del modelo ($\\Delta t = (1/25) s$)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x0 = np.array([0,0])\n",
    "angle = 80*degree\n",
    "v0 = 10*np.array([np.cos(angle), np.sin(angle)])\n",
    "\n",
    "a = np.array([0, - 9.8])\n",
    "t = np.arange(0,2.01,dt)\n",
    "\n",
    "noise = 0.05\n",
    "\n",
    "# trayectoria verdadera (desconocida en realidad)\n",
    "Zt = xt,yt = ht.col(x0)  +  ht.col(v0)* ht.row(t) + 1/2 * ht.col(a) * ht.row(t**2)\n",
    "\n",
    "# trayectoria observada\n",
    "Z  = xo,yo = Zt + noise*np.random.randn(2,len(t))\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(xo,yo,'.-',markersize=10);\n",
    "plt.axis('equal'); plt.grid(); plt.xlabel('$x$ (m)'); plt.ylabel('$y$ (m)');\n",
    "plt.title('trayectoria observada ($\\Delta t = (1/25) s$)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# estado que Kalman va actualizando. Este es el valor inicial\n",
    "\n",
    "             # x, y, vx, vy\n",
    "mu = np.array([0,0,0,0])\n",
    "            # sus incertidumbres\n",
    "P  = np.diag([100,100,100,100])**2\n",
    "#res = [(mu,P,mu)]\n",
    "res=[]\n",
    "N = 15  # para tomar un tramo inicial y ver qué pasa si luego se pierde la observación\n",
    "\n",
    "sigmaM = 0.001   # ruido del modelo\n",
    "sigmaZ = 3*noise  # debería ser igual al ruido de media del proceso de imagen. 10 pixels pje.\n",
    "\n",
    "Q = sigmaM**2 * np.eye(4)\n",
    "R = sigmaZ**2 * np.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "                                    # z es la medida del centro de la pelota observada\n",
    "                                    # mu es la estimación filtrada actualizada\n",
    "for z in Z.T[1:N]:\n",
    "    mu,P,pred = kalman(mu,P,F,Q,B,a,z,H,R)\n",
    "    res += [[mu,P,pred]]\n",
    "\n",
    "for _ in range(50-N):\n",
    "    mu,P,pred = kalman(mu,P,F,Q,B,a,None,H,R)  # aquí solo continuamos la predicción\n",
    "    res += [[mu,P,pred]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xe = [mu[0] for mu,_,_ in res]             # coordenada x estimada\n",
    "xu = [2*np.sqrt(P[0,0]) for _,P,_ in res]  # su incertidumbre\n",
    "\n",
    "ye = [mu[1] for mu,_,_ in res]             # lo mismo para y\n",
    "yu = [2*np.sqrt(P[1,1]) for _,P,_ in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "for k in range(len(xe)):\n",
    "    ax.add_patch(Ellipse(xy=(xe[k],ye[k]), width=xu[k], height=yu[k], angle = 0, alpha=0.2))\n",
    "\n",
    "plt.plot(xe,ye,lw=1)\n",
    "plt.plot(xo[1:N],yo[1:N])#,xe,ze);\n",
    "plt.plot(xt,yt,lw=0.5,color='gray'); plt.grid()\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "rc('animation', html='html5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "plt.close();\n",
    "ax.set_xlim(( -1, 4))\n",
    "ax.set_ylim(( 0, 5))\n",
    "\n",
    "line1, = ax.plot([], [], lw=1)\n",
    "line2, = ax.plot([],[])\n",
    "line3, = ax.plot([],[],'.',markersize=15)\n",
    "line4, = ax.plot([],[])\n",
    "line5, = ax.plot([],[])\n",
    "line6, = ax.plot(xt,yt,lw=0.5,color='gray')\n",
    "\n",
    "mu0 = np.array([0,0,0,0])\n",
    "            # sus incertidumbres \n",
    "P0  = np.diag([10,10,10,10])**2\n",
    "#res = [(mu,P,mu)]\n",
    "\n",
    "def animate(i):\n",
    "    global mu,P\n",
    "    N = i\n",
    "    res=[]\n",
    "    mu = mu0\n",
    "    P  = P0\n",
    "    for z in Z.T[1:N]:\n",
    "        mu,P,pred = kalman(mu,P,F,Q,B,a,z,H,R)\n",
    "        #print(mu)\n",
    "        res += [(mu,P,pred)]\n",
    "\n",
    "    for _ in range(len(Z.T)-N):\n",
    "        mu,P,pred = kalman(mu,P,F,Q,B,a,None,H,R)  # aquí solo continuamos la predicción\n",
    "        res += [(mu,P,pred)]\n",
    "\n",
    "\n",
    "    xe = np.array([mu[0] for mu,_,_ in res])\n",
    "    xu = np.array([2*np.sqrt(P[0,0]) for _,P,_ in res])\n",
    "\n",
    "    ye = np.array([mu[1] for mu,_,_ in res])\n",
    "    yu = np.array([2*np.sqrt(P[1,1]) for _,P,_ in res])\n",
    "\n",
    "    line1.set_data(xe,ye)\n",
    "    line2.set_data(xo[1:N],yo[1:N])\n",
    "    line3.set_data([xo[max(0,N-1)]],[yo[max(0,N-1)]])\n",
    "    line4.set_data(xe+xu,ye)\n",
    "    line5.set_data(xe-xu,ye)\n",
    "\n",
    "    return ()\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, init_func=lambda:[], frames=50, interval=4*1000/25, blit=True)\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
